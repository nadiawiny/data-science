{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzavkTqtFAMr"
      },
      "outputs": [],
      "source": [
        "##Quais as features, ou seja, as caracteristicas dos pacientes?\n",
        "## tossindo?\n",
        "## espirrando?\n",
        "## falta de ar?\n",
        "## febre?\n",
        "## vamos usar 0 para náo e 1 para sim\n",
        "\n",
        "gripados1 = [1, 1, 1, 1]\n",
        "gripados2 = [0, 1, 0, 1]\n",
        "gripados3 = [1, 1, 0, 0]\n",
        "gripados4 = [1, 1, 0, 1]\n",
        "\n",
        "alergico1 = [1, 1, 0, 0]\n",
        "alergico2 = [0, 1, 0, 0]\n",
        "alergico3 = [1, 0, 1, 0]\n",
        "alergico4 = [0, 1, 1, 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados = [gripados1, gripados2, gripados3, gripados4, alergico1, alergico2, alergico3, alergico4]\n",
        "# categoria 1 = gripado; categoria 0 = alérgico\n",
        "categorias = [1, 1, 1, 1, 0, 0, 0, 0]      ## supervisionado"
      ],
      "metadata": {
        "id": "bGebleW2Gufa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC"
      ],
      "metadata": {
        "id": "EqeA1auFIJ5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rodando nosso treino**"
      ],
      "metadata": {
        "id": "ck4AreFGIqOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = LinearSVC() #instancia\n",
        "modelo.fit(dados, categorias)  ## fit -- passar os meus dados de teino (variaveis, variavel resposta<quem é e quem não é - quem ta ou não>)\n",
        "                                ## modelo.fit(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ET8Ojb_IIp4E",
        "outputId": "7ab41918-ecb8-42c2-b7b0-bd8d4701cbc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definindo dados de teste**"
      ],
      "metadata": {
        "id": "vlm1RTVWJ5Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## passando os dados de teste\n",
        "\n",
        "paciente1 = [0, 1, 0, 1]\n",
        "paciente2 = [0, 0, 0, 0]\n",
        "paciente3 = [1, 1, 1, 1]\n",
        "paciente4 = [0, 1, 0, 1]\n",
        "\n",
        "dados_teste = [paciente1, paciente2, paciente3, paciente4]"
      ],
      "metadata": {
        "id": "zcBQhOdiJm99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testando**"
      ],
      "metadata": {
        "id": "g7xceo1jK4pM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.predict(dados_teste)  ## predict não me pede a variavel resposta, ele já me dar o retorno"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhdrduAOKkRU",
        "outputId": "28f15718-65d5-430c-e379-b5fc945a6102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dado um novo paciente, vamos avaliar a possibilidade de ele estar gripado**"
      ],
      "metadata": {
        "id": "5flgmZIULZ_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "novo_paciente = [0, 1, 0, 0]\n",
        "modelo.predict([novo_paciente])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-9yYLZ6LQ_k",
        "outputId": "46b49b70-972b-4773-9820-1e997ab4950a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (modelo.predict([novo_paciente]) == 0):\n",
        "  print('Paciente potencialmente alérgico')\n",
        "else:\n",
        "  print('Paciente potencialmente gripado')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qgpD3J6L3Q0",
        "outputId": "04d63757-35ff-4b02-d120-12415ef32953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paciente potencialmente alérgico\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vamos salvar a aplicação do nosso modelo dobre os dados de teste na variável predições**"
      ],
      "metadata": {
        "id": "HgtJ8CQKOD9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicoes = modelo.predict(dados_teste)"
      ],
      "metadata": {
        "id": "E6o2X5seOEME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Vamos supor que temos casos com exames que confirmaram o seguinte sobre os pacientes terem gripe ou não.\n",
        "## vamos comparar nosso modelo com a realidade\n",
        "\n",
        "exames = [1, 0, 1, 0]"
      ],
      "metadata": {
        "id": "dBZ5Vnf5OQ9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicoes == exames ## comparação"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4Cv8piVOVdE",
        "outputId": "3c8e75c0-d7b5-4fd3-9d71-b62c2f8a4f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True, False])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## total de acertos do nosso modelo:\n",
        "\n",
        "total_acertos = (predicoes == exames).sum()\n",
        "total_acertos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKl0jsDgOsfF",
        "outputId": "817f2781-5353-422a-ee8c-8deab2fb3aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_predicoes = len(dados_teste)\n",
        "total_predicoes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGBCEWBEPGh0",
        "outputId": "0ec11858-9706-46e1-ca31-67c2b826892a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## qual foi nossa taxa de sucesso?\n",
        "taxa_sucesso = total_acertos / total_predicoes *100\n",
        "taxa_sucesso"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7WVX6iwPuJk",
        "outputId": "9a603d27-c1d3-4162-ba2d-8e1556273159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75.0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('A taxa de sucesso do seu modelo preditivo foi de ', taxa_sucesso, '%. ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNP02mssP-t0",
        "outputId": "99c7b0dc-6481-4019-a2e9-524042405dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A taxa de sucesso do seu modelo preditivo foi de  75.0 %. \n"
          ]
        }
      ]
    }
  ]
}